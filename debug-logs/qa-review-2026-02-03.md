# QA Review - 2026-02-03

**Reviewed by:** 3 QA Agents (automated review)
**Files Reviewed:**
- `gpu_deploy_llm/web/server.py`
- `gpu_deploy_llm/client/shopper.py`
- `gpu_deploy_llm/client/models.py`
- `gpu_deploy_llm/client/__init__.py`
- `gpu_deploy_llm/deploy/vllm.py`
- `gpu_deploy_llm/deploy/health.py`
- `gpu_deploy_llm/deploy/__init__.py`
- `gpu_deploy_llm/ssh/connection.py`
- `gpu_deploy_llm/ssh/__init__.py`

---

## Summary

| Severity | Count | Status |
|----------|-------|--------|
| Critical | 2 | Open |
| High | 10 | Open |
| Medium | 17 | Open |
| Low | 7 | Open |
| **Total** | **37** | |

---

## Critical Bugs

### QA1-001: Cancelled Test Continues Running
- **Severity:** Critical
- **File:** `gpu_deploy_llm/web/server.py`
- **Lines:** 788-789
- **Status:** Open

**Description:**
When a test is stopped via `/api/test/stop`, the `_cancelled` flag is set and `_current_test` is set to `None`. However, the actual asyncio task continues running in the background. The test will continue to emit events, use resources, and potentially create/cleanup sessions even though the user believes it was stopped.

**Code:**
```python
@app.post("/api/test/stop")
async def stop_test():
    global _current_test
    async with _test_lock:
        if _current_test:
            _current_test._cancelled = True
            _current_test = None  # BUG: Task still running!
    return JSONResponse({"status": "stopped"})
```

**Fix:** Store task reference and call `task.cancel()`.

---

### QA3-001: Command Injection Vulnerability in SSH Commands
- **Severity:** Critical
- **File:** `gpu_deploy_llm/deploy/vllm.py`
- **Lines:** 436-445, 583-614
- **Status:** Open

**Description:**
User-controlled values (`config.model_id`, `config.api_key`, `config.quantization.value`) are interpolated directly into shell commands without sanitization. An attacker who can control the model ID or API key could inject arbitrary shell commands.

**Code:**
```python
cmd_parts = [
    f"--model {config.model_id}",  # VULNERABLE
    f"--api-key {config.api_key}",  # VULNERABLE
]
```

**Example attack:** `config.model_id = "foo; rm -rf / #"`

**Fix:** Use `shlex.quote()` for all user-controlled values.

---

## High Priority Bugs

### QA1-002: Swallowed Exception in Error Cleanup
- **Severity:** High
- **File:** `gpu_deploy_llm/web/server.py`
- **Lines:** 467-468
- **Status:** Open

**Description:**
In the test error handler, if session cleanup fails, the exception is completely silenced with a bare `except Exception: pass`. This makes it impossible to debug cleanup failures, and users won't know if orphaned sessions were left running (costing money).

**Code:**
```python
if self.session_id and self.config.auto_cleanup:
    try:
        async with ShopperClient(self.shopper_url) as client:
            await client.force_destroy(self.session_id)
    except Exception:
        pass  # Silent failure
```

**Fix:** Log the exception: `logger.warning(f"Cleanup failed: {e}")`

---

### QA1-003: Silent Exception Swallowing in Status Endpoint
- **Severity:** High
- **File:** `gpu_deploy_llm/web/server.py`
- **Lines:** 582-594
- **Status:** Open

**Description:**
The `/api/status` endpoint has multiple try/except blocks that silently swallow exceptions. When the shopper is having issues, the status endpoint returns partial data without any indication of what failed.

**Code:**
```python
try:
    health = await client.health_check()
    status["shopper"]["healthy"] = True
except Exception:
    pass  # No logging
```

**Fix:** Add debug logging and optional error fields in response.

---

### QA1-004: Race Condition Between Broadcast and Connection Removal
- **Severity:** High
- **File:** `gpu_deploy_llm/web/server.py`
- **Lines:** 521-535
- **Status:** Open

**Description:**
The `difference_update` on line 534-535 could remove connections that weren't in the original snapshot if new connections were added/removed between snapshot and cleanup.

**Fix:** Use `discard()` in a loop instead of `difference_update()`.

---

### QA2-001: HTTP Client Resource Leak on Init Exception
- **Severity:** High
- **File:** `gpu_deploy_llm/client/shopper.py`
- **Lines:** 93-102
- **Status:** Open

**Description:**
If an exception occurs after the httpx.AsyncClient is created but before `__aexit__` is called, the client will leak. Also, using the client without the context manager leaves connections open.

**Fix:** Add try/except in `__aenter__` and add explicit `close()` method.

---

### QA2-002: Network Exceptions Not Caught in _request Method
- **Severity:** High
- **File:** `gpu_deploy_llm/client/shopper.py`
- **Lines:** 133-146
- **Status:** Open

**Description:**
The `_request` method does not catch network-level exceptions (`httpx.ConnectError`, `httpx.TimeoutException`). These bubble up as raw httpx exceptions rather than being wrapped in `ShopperAPIError`.

**Code:**
```python
response = await self.client.request(method, path, **kwargs)  # Can raise httpx exceptions
```

**Fix:** Wrap in try/except and convert to `ShopperAPIError`.

---

### QA2-009: Fabricated Session Objects Mask Real State
- **Severity:** High
- **File:** `gpu_deploy_llm/client/shopper.py`
- **Lines:** 453-466, 490-515
- **Status:** Open

**Description:**
In `signal_done` and `force_destroy`, when the API returns 204 No Content, the code fabricates a Session object with hardcoded values like `status=STOPPED`. This masks the actual state - the session might still be running.

**Code:**
```python
if response.status_code == 204:
    return Session(
        id=session_id,
        status=SessionStatus.STOPPED,  # Assumed, not confirmed!
        provider="unknown",
        ...
    )
```

**Fix:** Return `Optional[Session]` or a new `SessionActionResult` type.

---

### QA3-002: API Key Visible in Process List
- **Severity:** High
- **File:** `gpu_deploy_llm/deploy/vllm.py`
- **Lines:** 444, 463, 596
- **Status:** Open

**Description:**
The API key is passed as a command-line argument (`--api-key {config.api_key}`). On Linux, command-line arguments are visible to all users via `/proc/{pid}/cmdline` or `ps aux`.

**Fix:** Use environment variables instead of command-line arguments.

---

### QA3-003: API Key Leaked in SSH Curl Commands
- **Severity:** High
- **File:** `gpu_deploy_llm/deploy/health.py`
- **Lines:** 337-339, 407-411
- **Status:** Open

**Description:**
The API key is embedded directly in curl commands sent over SSH. These may be logged by shell history or process monitoring.

**Code:**
```python
result = await self.ssh.run(
    f"curl -s -H 'Authorization: Bearer {self.api_key}' http://localhost:{port}/v1/models",
)
```

**Fix:** Use environment variables or write header to temp file.

---

### QA3-004: Docker Container Not Cleaned Up on Failure
- **Severity:** High
- **File:** `gpu_deploy_llm/deploy/vllm.py`
- **Lines:** 132-186
- **Status:** Open

**Description:**
If `_start_container()` succeeds but `_wait_for_container()` fails, the container remains running. The exception handler collects logs but never stops/removes the container.

**Fix:** Add container cleanup in the exception handler.

---

### QA3-005: vLLM Process Not Killed on Deployment Failure
- **Severity:** High
- **File:** `gpu_deploy_llm/deploy/vllm.py`
- **Lines:** 188-235
- **Status:** Open

**Description:**
If `_start_vllm_process()` starts the process but verification fails (e.g., PID changed indicating restart loop), the orphaned vLLM process is never killed, leaving GPU memory consumed.

**Fix:** Add `_kill_existing_vllm()` call in exception handler.

---

## Medium Priority Bugs

### QA1-005: Deprecated datetime.utcnow() Usage
- **Severity:** Medium
- **File:** `gpu_deploy_llm/web/server.py`
- **Line:** 67
- **Status:** Open

**Description:** `datetime.utcnow()` is deprecated in Python 3.12+.

**Fix:** Use `datetime.now(timezone.utc)`

---

### QA1-006: Missing Validation on TestConfig Fields
- **Severity:** Medium
- **File:** `gpu_deploy_llm/web/server.py`
- **Lines:** 73-83
- **Status:** Open

**Description:** No validation for negative prices, zero reservation hours, invalid quantization values.

**Fix:** Add Pydantic validators.

---

### QA1-007: WebSocket Sends Double-Encoded JSON
- **Severity:** Medium
- **File:** `gpu_deploy_llm/web/server.py`
- **Lines:** 911-912
- **Status:** Open

**Description:** Status is JSON-encoded, then embedded as string in another JSON object.

**Fix:** Return dict directly, not JSONResponse.

---

### QA1-008: Task Done Callback Bug
- **Severity:** Medium
- **File:** `gpu_deploy_llm/web/server.py`
- **Lines:** 773-777
- **Status:** Open

**Description:** If task is cancelled, `t.exception()` raises `CancelledError` instead of returning it.

**Fix:** Wrap in proper function with try/except for CancelledError.

---

### QA2-003: Race Condition in wait_for_ready Timeout
- **Severity:** Medium
- **File:** `gpu_deploy_llm/client/shopper.py`
- **Lines:** 235-250
- **Status:** Open

**Description:** Timeout check before sleep can cause method to run longer than specified timeout.

**Fix:** Check remaining time and use `min(interval, remaining)` for sleep.

---

### QA2-004: Broad Exception Swallows Critical Errors
- **Severity:** Medium
- **File:** `gpu_deploy_llm/client/shopper.py`
- **Lines:** 245-246
- **Status:** Open

**Description:** `except Exception` catches CancelledError and other critical exceptions.

**Fix:** Catch specific exceptions, re-raise CancelledError.

---

### QA2-005: Retry-After Header Parsed Without Validation
- **Severity:** Medium
- **File:** `gpu_deploy_llm/client/shopper.py`
- **Lines:** 160-166
- **Status:** Open

**Description:** `int(retry_after)` can raise ValueError if header is malformed.

**Fix:** Wrap in try/except ValueError.

---

### QA2-006: session_id Not Validated Before URL Construction
- **Severity:** Medium
- **File:** `gpu_deploy_llm/client/shopper.py`
- **Lines:** 375+
- **Status:** Open

**Description:** Empty strings or strings with slashes could cause path traversal issues.

**Fix:** Add `_validate_session_id()` helper.

---

### QA2-007: Inconsistent Response Parsing with Dangerous Fallback
- **Severity:** Medium
- **File:** `gpu_deploy_llm/client/shopper.py`
- **Lines:** 369-373
- **Status:** Open

**Description:** `Session(**data.get("session", data))` uses entire response as fallback.

**Fix:** Require "session" key, raise error if missing.

---

### QA2-010: No Retry Logic for Transient Failures
- **Severity:** Medium
- **File:** `gpu_deploy_llm/client/shopper.py`
- **Lines:** 133-146
- **Status:** Open

**Description:** No automatic retry for 5xx errors or connection resets.

**Fix:** Add optional retry with exponential backoff.

---

### QA3-006: PID Comparison Unreliable for Restart Detection
- **Severity:** Medium
- **File:** `gpu_deploy_llm/deploy/vllm.py`
- **Lines:** 485-512
- **Status:** Open

**Description:** `pgrep | head -1` may return different PIDs if multiple processes exist.

**Fix:** Use `pgrep -n` (newest) or track actual PID from nohup.

---

### QA3-007: Key File Not Deleted on SSH Connect Failure
- **Severity:** Medium
- **File:** `gpu_deploy_llm/ssh/connection.py`
- **Lines:** 140-173
- **Status:** Open

**Description:** Temporary key file leaks if connection fails.

**Fix:** Add cleanup in exception handlers.

---

### QA3-008: HTTP Client Leak Without Context Manager
- **Severity:** Medium
- **File:** `gpu_deploy_llm/deploy/health.py`
- **Lines:** 568-572
- **Status:** Open

**Description:** `_get_client()` creates client that's never closed if not using `async with`.

**Fix:** Add `close()` method or require context manager.

---

### QA3-009: No Timeout on wait_closed() Calls
- **Severity:** Medium
- **File:** `gpu_deploy_llm/ssh/connection.py`
- **Lines:** 179, 442
- **Status:** Open

**Description:** `wait_closed()` can hang indefinitely.

**Fix:** Wrap in `asyncio.wait_for(..., timeout=10.0)`.

---

### QA3-010: Swallowed Exception in Container Log Collection
- **Severity:** Medium
- **File:** `gpu_deploy_llm/deploy/vllm.py`
- **Lines:** 177-182
- **Status:** Open

**Description:** `except Exception: pass` silently swallows log collection errors.

**Fix:** Add `logger.warning()`.

---

### QA3-011: Command Injection in file_exists()
- **Severity:** Medium
- **File:** `gpu_deploy_llm/ssh/connection.py`
- **Lines:** 358-361
- **Status:** Open

**Description:** `path` parameter used in shell command without sanitization.

**Fix:** Use `shlex.quote(path)`.

---

### QA3-012: Command Injection in get_container_logs()
- **Severity:** Medium
- **File:** `gpu_deploy_llm/ssh/connection.py`
- **Line:** 334
- **Status:** Open

**Description:** `container_name` and `tail` used without sanitization.

**Fix:** Use `shlex.quote()` and `int()` validation.

---

## Low Priority Bugs

### QA1-009: File Read Without Error Handling
- **Severity:** Low
- **File:** `gpu_deploy_llm/web/server.py`
- **Lines:** 559-564
- **Status:** Open

**Description:** Dashboard HTML read without handling IOError.

---

### QA1-010: WebSocket Accept Called Inside Lock
- **Severity:** Low
- **File:** `gpu_deploy_llm/web/server.py`
- **Lines:** 898-907
- **Status:** Open

**Description:** Holding lock during I/O could block other operations.

---

### QA1-011: Unvalidated Limit Parameter
- **Severity:** Low
- **File:** `gpu_deploy_llm/web/server.py`
- **Lines:** 637-638
- **Status:** Open

**Description:** `/api/sessions` limit parameter has no upper bound.

---

### QA2-008: String vs Enum Type Mismatch
- **Severity:** Low
- **File:** `gpu_deploy_llm/client/shopper.py`
- **Lines:** 298-358
- **Status:** Open

**Description:** `storage_policy` typed as string but model expects enum.

---

### QA2-011: Missing Exports in __init__.py
- **Severity:** Low
- **File:** `gpu_deploy_llm/client/__init__.py`
- **Lines:** 1-26
- **Status:** Open

**Description:** Several public types not exported.

---

### QA3-013: Integer Parsing in GPU Memory Calculation
- **Severity:** Low
- **File:** `gpu_deploy_llm/deploy/health.py`
- **Line:** 107
- **Status:** Open

**Description:** Division by zero possible if parsing fails.

---

### QA3-014: Host Key Verification Disabled
- **Severity:** Low
- **File:** `gpu_deploy_llm/ssh/connection.py`
- **Line:** 151
- **Status:** Open

**Description:** `known_hosts=None` disables SSH host key verification.

---

### QA3-015: SSH Failure Handling in Wait Loop
- **Severity:** Low
- **File:** `gpu_deploy_llm/deploy/vllm.py`
- **Lines:** 624-643
- **Status:** Open

**Description:** No retry for transient SSH errors during container wait.

---

## Cross-Reference with Previous Bugs

| Previous Bug | Status | Notes |
|--------------|--------|-------|
| BUG-001 (Race condition in _current_test) | Fixed | Has `_test_lock` now |
| BUG-002 (Set modification during iteration) | Fixed | Uses snapshot pattern |
| BUG-003 (Unbounded WebSocket connections) | Fixed | Has MAX_WEBSOCKET_CONNECTIONS |
| BUG-004 (Fire-and-forget task) | Fixed | Has done_callback |
| BUG-005 (Swallowed exception in cleanup) | Open | = QA1-002 |
| BUG-006 (Missing cancelled flag check) | Fixed | Has `_cancelled` checks |
| BUG-007 (Silent exception in status) | Open | = QA1-003 |
| BUG-008 (datetime.utcnow deprecation) | Open | = QA1-005 |
| BUG-009 (Missing TestConfig validation) | Open | = QA1-006 |
| BUG-010 (WebSocket double-encoded JSON) | Open | = QA1-007 |
